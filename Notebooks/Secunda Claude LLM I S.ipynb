{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nProject Manager Agent for Multi-Agent System\n- Manages tasks and assignments\n- Coordinates programmer agents\n- Provides feedback and improvement suggestions\n- Uses small (~1B parameter) LLM for reasoning\n\"\"\"\n\nimport asyncio\nimport json\nimport uuid\nfrom typing import Dict, List, Optional, Union, Any, Tuple\nfrom dataclasses import dataclass, field\nimport logging\n\nfrom base_agent_framework import (\n    AgentRole, ExpertiseArea, MessageType, Task, Message,\n    LocalLLMManager, KnowledgeBase, ThoughtMemory, Thought\n)\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass ProgrammerMetrics:\n    \"\"\"Metrics tracked for each programmer agent\"\"\"\n    task_completion_rate: float = 0.0\n    code_quality_score: float = 0.0\n    knowledge_application: float = 0.0\n    learning_progress: Dict[str, float] = field(default_factory=dict)\n    recent_performance: List[float] = field(default_factory=list)\n    \n@dataclass\nclass ProjectStatus:\n    \"\"\"Status tracker for the overall project\"\"\"\n    total_tasks: int = 0\n    completed_tasks: int = 0\n    in_progress_tasks: int = 0\n    blocked_tasks: int = 0\n    task_completion_rate: float = 0.0\n    programmer_performance: Dict[str, ProgrammerMetrics] = field(default_factory=dict)\n\nclass ProjectManagerAgent:\n    \"\"\"Project Manager agent implementation using locally deployed small LLMs\"\"\"\n    \n    def __init__(\n        self,\n        agent_id: str,\n        llm_manager: LocalLLMManager,\n        knowledge_base: KnowledgeBase,\n        message_queue: asyncio.Queue,\n    ):\n        self.agent_id = agent_id\n        self.role = AgentRole.PROJECT_MANAGER\n        self.llm_manager = llm_manager\n        self.knowledge_base = knowledge_base\n        self.message_queue = message_queue\n        \n        # Internal state\n        self.task_list: List[Task] = []\n        self.programmer_registry: Dict[str, Dict[str, Any]] = {}\n        self.project_status = ProjectStatus()\n        self.thought_memory = ThoughtMemory(max_thoughts=1000)\n        \n        # Initialize task ID counter\n        self.next_task_id = 1\n        \n        logger.info(f\"Project Manager Agent {agent_id} initialized\")\n    \n    async def start(self):\n        \"\"\"Start the agent's main processing loop\"\"\"\n        logger.info(f\"Project Manager Agent {self.agent_id} starting\")\n        while True:\n            try:\n                message = await self.message_queue.get()\n                await self.process_message(message)\n                self.message_queue.task_done()\n            except Exception as e:\n                logger.error(f\"Error processing message: {e}\")\n                import traceback\n                logger.error(traceback.format_exc())\n\n    async def process_message(self, message: Message):\n        \"\"\"Process incoming messages based on their type\"\"\"\n        logger.info(f\"Processing message from {message.sender}: {message.message_type}\")\n        \n        if message.recipient != self.agent_id and message.recipient != \"all\":\n            return  # Not for this agent\n            \n        # Generate thoughts about the message\n        context = f\"Message from {message.sender} of type {message.message_type}:\\n\"\n        context += json.dumps(message.content, indent=2)\n        \n        thought = await self.llm_manager.generate_thought(\n            agent_role=self.role,\n            thought_type=\"Observation\",\n            context=context\n        )\n        \n        if thought:\n            self.thought_memory.add_thought(thought)\n        \n        # Process based on message type\n        if message.message_type == MessageType.STATUS_UPDATE:\n            await self.handle_status_update(message)\n        elif message.message_type == MessageType.TECHNICAL_QUERY:\n            await self.handle_technical_query(message)\n        elif message.message_type == MessageType.REVIEW_REQUEST:\n            await self.handle_review_request(message)\n        elif message.message_type == MessageType.LEARNING_UPDATE:\n            await self.handle_learning_update(message)\n        else:\n            logger.warning(f\"Unknown message type: {message.message_type}\")\n    \n    async def handle_status_update(self, message: Message):\n        \"\"\"Handle status update messages from programmer agents\"\"\"\n        sender = message.sender\n        content = message.content\n        \n        # Update task status if provided\n        if \"task_id\" in content and \"status\" in content:\n            task_id = content[\"task_id\"]\n            new_status = content[\"status\"]\n            \n            # Find the task and update its status\n            for task in self.task_list:\n                if task.id == task_id:\n                    old_status = task.status\n                    task.status = new_status\n                    \n                    # Generate thought about status change\n                    context = f\"Task {task_id} changed status from {old_status} to {new_status}\"\n                    thought = await self.llm_manager.generate_thought(\n                        agent_role=self.role,\n                        thought_type=\"Analysis\",\n                        context=context\n                    )\n                    \n                    if thought:\n                        self.thought_memory.add_thought(thought)\n                    \n                    # Update project status\n                    await self.update_project_status()\n                    \n                    # Provide feedback to the programmer\n                    await self.provide_feedback(sender, task)\n                    break\n        \n        # Update programmer metrics if provided\n        if \"metrics\" in content:\n            metrics = content[\"metrics\"]\n            if sender in self.programmer_registry:\n                # Update existing metrics\n                self.programmer_registry[sender][\"metrics\"].update(metrics)\n            else:\n                # Create new entry\n                self.programmer_registry[sender] = {\n                    \"metrics\": metrics,\n                    \"expertise\": content.get(\"expertise\", [])\n                }\n    \n    async def handle_technical_query(self, message: Message):\n        \"\"\"Handle technical queries from programmer agents\"\"\"\n        sender = message.sender\n        content = message.content\n        \n        # In a real PM agent, we'd consider if this needs to be forwarded to an architect\n        # For now, we'll just respond with knowledge base info\n        query = content.get(\"query\", \"\")\n        \n        # Query the knowledge base\n        knowledge_results = await self.knowledge_base.query_knowledge(query)\n        \n        # Get relevant thoughts\n        relevant_thoughts = self.thought_memory.get_relevant_thoughts(query)\n        thought_context = \"\\n\".join([\n            f\"- {t.thought_type}: {t.content} (confidence: {t.confidence})\" \n            for t in relevant_thoughts\n        ])\n        \n        # Prepare context for response generation\n        context = f\"Technical query from {sender}: {query}\\n\\n\"\n        context += \"Relevant knowledge:\\n\" + \"\\n\".join(knowledge_results) + \"\\n\\n\"\n        context += \"Relevant past thoughts:\\n\" + thought_context\n        \n        # Generate response thought\n        thought = await self.llm_manager.generate_thought(\n            agent_role=self.role,\n            thought_type=\"Decision\",\n            context=context\n        )\n        \n        if thought:\n            self.thought_memory.add_thought(thought)\n            \n            # Send response back to programmer\n            response_message = Message(\n                sender=self.agent_id,\n                recipient=sender,\n                message_type=MessageType.TECHNICAL_QUERY,\n                content={\n                    \"response\": thought.content,\n                    \"confidence\": thought.confidence,\n                    \"references\": knowledge_results[:2]  # Just send top 2 references\n                }\n            )\n            \n            await self.send_message(response_message)\n    \n    async def handle_review_request(self, message: Message):\n        \"\"\"Handle code review requests from programmer agents\"\"\"\n        sender = message.sender\n        content = message.content\n        \n        code = content.get(\"code\", \"\")\n        task_id = content.get(\"task_id\", \"\")\n        \n        # Query knowledge base for relevant patterns\n        knowledge_results = await self.knowledge_base.query_knowledge(\n            f\"code review {content.get('language', '')} {content.get('component', '')}\"\n        )\n        \n        # Prepare context for review\n        context = f\"Code review request from {sender} for task {task_id}:\\n\\n\"\n        context += f\"```\\n{code}\\n```\\n\\n\"\n        context += \"Relevant knowledge:\\n\" + \"\\n\".join(knowledge_results)\n        \n        # Generate review thought\n        thought = await self.llm_manager.generate_thought(\n            agent_role=self.role,\n            thought_type=\"Analysis\",\n            context=context\n        )\n        \n        if thought:\n            self.thought_memory.add_thought(thought)\n            \n            # Request an additional decision thought based on the analysis\n            decision_context = f\"Based on code review:\\n{thought.content}\\n\\nWhat feedback should be provided?\"\n            decision_thought = await self.llm_manager.generate_thought(\n                agent_role=self.role,\n                thought_type=\"Decision\",\n                context=decision_context\n            )\n            \n            if decision_thought:\n                self.thought_memory.add_thought(decision_thought)\n                \n                # Generate a learning opportunity\n                learning_context = f\"Based on this code review, what learning opportunity can be identified for {sender}?\"\n                learning_thought = await self.llm_manager.generate_thought(\n                    agent_role=self.role,\n                    thought_type=\"Learning\",\n                    context=learning_context\n                )\n                \n                if learning_thought:\n                    self.thought_memory.add_thought(learning_thought)\n                \n                # Send response back to programmer\n                response_message = Message(\n                    sender=self.agent_id,\n                    recipient=sender,\n                    message_type=MessageType.REVIEW_REQUEST,\n                    content={\n                        \"task_id\": task_id,\n                        \"feedback\": decision_thought.content,\n                        \"improvements\": learning_thought.content if learning_thought else \"\",\n                        \"approved\": \"approved\" in decision_thought.content.lower()\n                    }\n                )\n                \n                await self.send_message(response_message)\n    \n    async def handle_learning_update(self, message: Message):\n        \"\"\"Handle learning updates from programmer agents\"\"\"\n        sender = message.sender\n        content = message.content\n        \n        learning_area = content.get(\"area\", \"\")\n        progress = content.get(\"progress\", 0.0)\n        notes = content.get(\"notes\", \"\")\n        \n        # Update programmer metrics\n        if sender in self.programmer_registry:\n            if \"learning_progress\" not in self.programmer_registry[sender]:\n                self.programmer_registry[sender][\"learning_progress\"] = {}\n                \n            self.programmer_registry[sender][\"learning_progress\"][learning_area] = progress\n        \n        # Generate thought about learning progress\n        context = f\"Learning update from {sender} on {learning_area}:\\n{notes}\\nProgress: {progress}\"\n        thought = await self.llm_manager.generate_thought(\n            agent_role=self.role,\n            thought_type=\"Learning\",\n            context=context\n        )\n        \n        if thought:\n            self.thought_memory.add_thought(thought)\n            \n        # Query knowledge base for related resources\n        knowledge_results = await self.knowledge_base.query_knowledge(learning_area)\n        \n        # Prepare context for suggestion generation\n        suggestion_context = f\"Learning update from {sender} on {learning_area}:\\n{notes}\\n\\n\"\n        suggestion_context += \"Relevant knowledge:\\n\" + \"\\n\".join(knowledge_results)\n        \n        # Generate suggestion thought\n        suggestion_thought = await self.llm_manager.generate_thought(\n            agent_role=self.role,\n            thought_type=\"Decision\",\n            context=suggestion_context\n        )\n        \n        if suggestion_thought:\n            self.thought_memory.add_thought(suggestion_thought)\n            \n            # Send learning suggestions\n            response_message = Message(\n                sender=self.agent_id,\n                recipient=sender,\n                message_type=MessageType.LEARNING_UPDATE,\n                content={\n                    \"area\": learning_area,\n                    \"suggestions\": suggestion_thought.content,\n                    \"resources\": knowledge_results[:2]  # Just top 2 resources\n                }\n            )\n            \n            await self.send_message(response_message)\n    \n    async def create_task(self, title: str, description: str, \n                        required_expertise: List[ExpertiseArea], priority: int = 1) -> Task:\n        \"\"\"Create a new task and add it to the task list\"\"\"\n        task_id = f\"TASK-{self.next_task_id}\"\n        self.next_task_id += 1\n        \n        task = Task(\n            id=task_id,\n            title=title,\n            description=description,\n            required_expertise=required_expertise,\n            priority=priority\n        )\n        \n        self.task_list.append(task)\n        self.project_status.total_tasks += 1\n        \n        # Generate thought about new task\n        context = f\"Created new task: {title}\\n{description}\\nRequired expertise: {required_expertise}\"\n        thought = await self.llm_manager.generate_thought(\n            agent_role=self.role,\n            thought_type=\"Decision\",\n            context=context\n        )\n        \n        if thought:\n            self.thought_memory.add_thought(thought)\n        \n        logger.info(f\"Created new task: {task_id} - {title}\")\n        return task\n    \n    async def assign_task(self, task: Task) -> bool:\n        \"\"\"Assign a task to the most suitable programmer\"\"\"\n        # Find programmers with matching expertise\n        candidates = []\n        for prog_id, prog_info in self.programmer_registry.items():\n            expertise_match = any(\n                exp in prog_info.get(\"expertise\", []) \n                for exp in task.required_expertise\n            )\n            \n            if expertise_match:\n                # Count current assigned tasks\n                current_tasks = sum(\n                    1 for t in self.task_list \n                    if t.assigned_to == prog_id and t.status != \"completed\"\n                )\n                \n                candidates.append((prog_id, current_tasks, prog_info))\n        \n        if not candidates:\n            logger.warning(f\"No suitable programmers found for task {task.id}\")\n            return False\n            \n        # Sort by workload (number of current tasks)\n        candidates.sort(key=lambda x: x[1])\n        selected_programmer = candidates[0][0]\n        \n        # Assign the task\n        task.assigned_to = selected_programmer\n        task.status = \"assigned\"\n        \n        # Generate thought about assignment\n        context = f\"Assigned task {task.id} to {selected_programmer}\"\n        thought = await self.llm_manager.generate_thought(\n            agent_role=self.role,\n            thought_type=\"Decision\",\n            context=context\n        )\n        \n        if thought:\n            self.thought_memory.add_thought(thought)\n        \n        # Send assignment message\n        assignment_message = Message(\n            sender=self.agent_id,\n            recipient=selected_programmer,\n            message_type=MessageType.TASK_ASSIGNMENT,\n            content={\n                \"task_id\": task.id,\n                \"title\": task.title,\n                \"description\": task.description,\n                \"priority\": task.priority\n            }\n        )\n        \n        await self.send_message(assignment_message)\n        logger.info(f\"Assigned task {task.id} to {selected_programmer}\")\n        return True\n    \n    async def update_project_status(self):\n        \"\"\"Update project status metrics\"\"\"\n        # Count tasks by status\n        completed = sum(1 for task in self.task_list if task.status == \"completed\")\n        in_progress = sum(1 for task in self.task_list if task.status in [\"assigned\", \"in_progress\"])\n        blocked = sum(1 for task in self.task_list if task.status == \"blocked\")\n        \n        # Update status\n        self.project_status.completed_tasks = completed\n        self.project_status.in_progress_tasks = in_progress\n        self.project_status.blocked_tasks = blocked\n        \n        # Calculate completion rate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}