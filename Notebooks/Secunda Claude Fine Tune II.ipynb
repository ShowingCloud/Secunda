{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport logging\nfrom typing import List, Dict, Union\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer, \n    TrainingArguments, \n    Trainer\n)\nfrom peft import (\n    LoraConfig, \n    get_peft_model, \n    PeftModel,\n    prepare_model_for_kbit_training\n)\nfrom datasets import Dataset, concatenate_datasets\nimport numpy as np\n\nclass ContinuousFineTuner:\n    \"\"\"\n    Advanced continuous fine-tuning strategy for language models\n    Supports multiple approaches to incremental learning\n    \"\"\"\n    def __init__(\n        self, \n        model_name: str,\n        cache_dir: str = \"./continuous_finetune_cache\",\n        max_memory_buffer: int = 10000\n    ):\n        \"\"\"\n        Initialize continuous fine-tuning manager\n        \n        Args:\n            model_name: Base model to fine-tune\n            cache_dir: Directory to store model checkpoints and data\n            max_memory_buffer: Maximum number of recent samples to retain\n        \"\"\"\n        self.model_name = model_name\n        self.cache_dir = cache_dir\n        self.max_memory_buffer = max_memory_buffer\n        \n        # Create directories\n        os.makedirs(cache_dir, exist_ok=True)\n        os.makedirs(os.path.join(cache_dir, \"checkpoints\"), exist_ok=True)\n        os.makedirs(os.path.join(cache_dir, \"memory_buffer\"), exist_ok=True)\n        \n        # Setup logging\n        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s - %(levelname)s - %(message)s',\n            filename=os.path.join(cache_dir, \"continuous_finetuning.log\")\n        )\n        self.logger = logging.getLogger(__name__)\n        \n        # Model components\n        self.base_model = None\n        self.tokenizer = None\n        self.current_model = None\n    \n    def load_base_model(self):\n        \"\"\"Load base model and tokenizer\"\"\"\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.base_model = AutoModelForCausalLM.from_pretrained(\n            self.model_name,\n            torch_dtype=torch.float16,\n            device_map=\"auto\"\n        )\n        self.current_model = self.base_model\n    \n    def _create_memory_buffer(self):\n        \"\"\"\n        Create a sliding window memory buffer for continuous learning\n        \n        Returns:\n            List of recent training samples\n        \"\"\"\n        buffer_path = os.path.join(self.cache_dir, \"memory_buffer\")\n        \n        # Load existing buffer files\n        buffer_files = [\n            os.path.join(buffer_path, f) \n            for f in os.listdir(buffer_path) \n            if f.endswith(\".pt\")\n        ]\n        \n        # Sort by modification time and keep most recent\n        buffer_files.sort(key=os.path.getmtime, reverse=True)\n        buffer_files = buffer_files[:self.max_memory_buffer]\n        \n        # Load tensors\n        memory_buffer = []\n        for file in buffer_files:\n            try:\n                memory_buffer.append(torch.load(file))\n            except Exception as e:\n                self.logger.warning(f\"Could not load memory buffer {file}: {e}\")\n        \n        return memory_buffer\n    \n    def continuous_fine_tune(\n        self, \n        new_data: Union[List[Dict], Dataset],\n        strategy: str = \"incremental\",\n        learning_rate: float = 1e-4,\n        buffer_ratio: float = 0.2\n    ):\n        \"\"\"\n        Continuous fine-tuning with multiple learning strategies\n        \n        Args:\n            new_data: New training data\n            strategy: Fine-tuning approach\n                - 'incremental': Add new data to existing knowledge\n                - 'adaptive': Dynamically adjust learning based on data distribution\n                - 'memory_replay': Use experience replay to prevent catastrophic forgetting\n            learning_rate: Base learning rate\n            buffer_ratio: Proportion of memory buffer to use in training\n        \"\"\"\n        # Ensure model is loaded\n        if not self.base_model:\n            self.load_base_model()\n        \n        # Prepare new dataset\n        if isinstance(new_data, list):\n            new_dataset = Dataset.from_list(new_data)\n        else:\n            new_dataset = new_data\n        \n        # Tokenize new data\n        def tokenize_function(examples):\n            return self.tokenizer(\n                examples['text'], \n                truncation=True, \n                padding='max_length', \n                max_length=512\n            )\n        \n        tokenized_new_data = new_dataset.map(\n            tokenize_function, \n            batched=True, \n            remove_columns=new_dataset.column_names\n        )\n        \n        # Strategies for continuous learning\n        if strategy == \"incremental\":\n            # Simple incremental learning\n            training_dataset = tokenized_new_data\n        \n        elif strategy == \"adaptive\":\n            # Dynamically adjust learning rate based on data novelty\n            novelty_score = self._compute_data_novelty(tokenized_new_data)\n            learning_rate *= novelty_score\n            training_dataset = tokenized_new_data\n        \n        elif strategy == \"memory_replay\":\n            # Experience replay to prevent catastrophic forgetting\n            memory_buffer = self._create_memory_buffer()\n            \n            # Convert memory buffer to dataset\n            buffer_dataset = Dataset.from_list(memory_buffer)\n            \n            # Combine new data with memory buffer\n            training_dataset = concatenate_datasets([\n                tokenized_new_data, \n                buffer_dataset\n            ])\n        \n        # LoRA configuration for efficient fine-tuning\n        peft_config = LoraConfig(\n            r=16,  # Rank of LoRA adaptation\n            lora_alpha=32,\n            target_modules=[\"q_proj\", \"v_proj\"],\n            lora_dropout=0.1,\n            bias=\"none\"\n        )\n        \n        # Prepare model for LoRA training\n        model_to_train = prepare_model_for_kbit_training(self.current_model)\n        peft_model = get_peft_model(model_to_train, peft_config)\n        \n        # Training arguments\n        training_args = TrainingArguments(\n            output_dir=os.path.join(self.cache_dir, \"checkpoints\"),\n            learning_rate=learning_rate,\n            per_device_train_batch_size=4,\n            num_train_epochs=1,  # Short epochs for continuous learning\n            logging_dir=os.path.join(self.cache_dir, \"logs\"),\n            save_strategy=\"steps\",\n            save_steps=100,\n            logging_steps=10\n        )\n        \n        # Trainer\n        trainer = Trainer(\n            model=peft_model,\n            args=training_args,\n            train_dataset=training_dataset\n        )\n        \n        # Train\n        trainer.train()\n        \n        # Save the fine-tuned model\n        checkpoint_path = os.path.join(\n            self.cache_dir, \n            f\"checkpoint_{len(new_data)}_samples\"\n        )\n        peft_model.save_pretrained(checkpoint_path)\n        \n        # Update current model\n        self.current_model = peft_model\n        \n        # Log training metrics\n        self.logger.info(f\"Continuous fine-tuning completed with {len(new_data)} new samples\")\n    \n    def _compute_data_novelty(self, dataset):\n        \"\"\"\n        Compute novelty score of new data relative to existing knowledge\n        \n        Args:\n            dataset: New dataset to evaluate\n        \n        Returns:\n            Novelty score (0-1)\n        \"\"\"\n        # Example simple novelty computation\n        # You might replace this with more sophisticated methods like:\n        # - Embedding-based distance metrics\n        # - Entropy of model predictions\n        # - Surprise-based novelty detection\n        \n        # Placeholder novelty computation\n        vocab_coverage = len(set(dataset['input_ids'].flatten())) / len(self.tokenizer.vocab)\n        return min(vocab_coverage, 1.0)\n    \n    def inference_with_continuous_model(self, prompt: str):\n        \"\"\"\n        Run inference with the continuously fine-tuned model\n        \n        Args:\n            prompt: Input prompt\n        \n        Returns:\n            Model generation\n        \"\"\"\n        # Ensure model is loaded\n        if not self.current_model:\n            self.load_base_model()\n        \n        # Tokenize input\n        inputs = self.tokenizer(\n            prompt, \n            return_tensors=\"pt\", \n            truncation=True, \n            max_length=512\n        ).to(self.current_model.device)\n        \n        # Generate\n        outputs = self.current_model.generate(\n            **inputs, \n            max_new_tokens=100, \n            do_sample=True, \n            temperature=0.7\n        )\n        \n        # Decode output\n        generated_text = self.tokenizer.decode(\n            outputs[0], \n            skip_special_tokens=True\n        )\n        \n        return generated_text\n\n# Example usage\nif __name__ == \"__main__\":\n    # Initialize continuous fine-tuner\n    continuous_tuner = ContinuousFineTuner(\n        model_name=\"microsoft/Phi-4-mini-instruct\"\n    )\n    \n    # Simulate continuous data stream\n    for batch_number in range(10):\n        # Simulate new data coming in\n        new_training_data = [\n            {\"text\": f\"New sample from batch {batch_number}\"}\n            for _ in range(100)\n        ]\n        \n        # Continuous fine-tuning\n        continuous_tuner.continuous_fine_tune(\n            new_data=new_training_data,\n            strategy=\"memory_replay\"\n        )\n        \n        # Optional: Periodic inference or evaluation\n        print(continuous_tuner.inference_with_continuous_model(\n            \"Explain the concept of continuous learning\"\n        ))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}