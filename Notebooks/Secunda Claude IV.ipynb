{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from typing import List, Dict, Optional, Union, TypedDict\nfrom datetime import datetime\nimport asyncio\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\nfrom sqlalchemy import create_engine, Column, String, JSON, DateTime, Integer, Float, ForeignKey\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, relationship\nimport json\nimport numpy as np\nfrom collections import deque\n\nBase = declarative_base()\n\nclass CommandExecutionRecord(Base):\n    __tablename__ = 'command_executions'\n    \n    id = Column(Integer, primary_key=True)\n    command = Column(String)\n    timestamp = Column(DateTime, default=datetime.utcnow)\n    stdout = Column(String)\n    stderr = Column(String)\n    syslog = Column(String)\n    system_state_before = Column(JSON)\n    system_state_after = Column(JSON)\n    interaction_history = Column(JSON)\n    agent_decisions = Column(JSON)\n    outcome_metrics = Column(JSON)\n    learning_annotations = Column(JSON)\n\nclass LearningExperience(Base):\n    __tablename__ = 'learning_experiences'\n    \n    id = Column(Integer, primary_key=True)\n    agent_id = Column(String)\n    command_execution_id = Column(Integer, ForeignKey('command_executions.id'))\n    expertise_area = Column(String)\n    success_metrics = Column(Float)\n    learned_patterns = Column(JSON)\n    improvement_areas = Column(JSON)\n    timestamp = Column(DateTime, default=datetime.utcnow)\n\nclass SystemStateSnapshot(TypedDict):\n    cpu_usage: float\n    memory_usage: float\n    disk_usage: Dict[str, float]\n    network_status: Dict[str, str]\n    running_processes: List[str]\n    error_logs: List[str]\n\nclass LearningMetrics(BaseModel):\n    command_success_rate: float = 0.0\n    error_recovery_rate: float = 0.0\n    interaction_efficiency: float = 0.0\n    pattern_recognition_score: float = 0.0\n    knowledge_application_rate: float = 0.0\n\nclass LearningMemory:\n    def __init__(self, max_size: int = 1000):\n        self.experiences = deque(maxlen=max_size)\n        self.pattern_frequency = {}\n        self.success_patterns = {}\n        self.error_patterns = {}\n        \n    def add_experience(self, experience: Dict):\n        self.experiences.append(experience)\n        self._update_patterns(experience)\n    \n    def _update_patterns(self, experience: Dict):\n        \"\"\"Update pattern recognition based on new experience\"\"\"\n        if experience.get('success', False):\n            pattern = self._extract_pattern(experience)\n            self.success_patterns[pattern] = self.success_patterns.get(pattern, 0) + 1\n        else:\n            error_pattern = self._extract_error_pattern(experience)\n            self.error_patterns[error_pattern] = self.error_patterns.get(error_pattern, 0) + 1\n\n    def _extract_pattern(self, experience: Dict) -> str:\n        \"\"\"Extract success pattern from experience\"\"\"\n        # Implement pattern extraction logic\n        return json.dumps(sorted(experience.get('key_factors', [])))\n\n    def _extract_error_pattern(self, experience: Dict) -> str:\n        \"\"\"Extract error pattern from experience\"\"\"\n        # Implement error pattern extraction logic\n        return json.dumps(sorted(experience.get('error_factors', [])))\n\nclass LearningProgrammerAgent(BaseAgent):\n    def __init__(self, \n                 name: str, \n                 expertise: List[str],\n                 model_path: str,\n                 db_session: sessionmaker):\n        super().__init__(name, model_path)\n        self.expertise = expertise\n        self.db_session = db_session\n        self.learning_memory = LearningMemory()\n        self.learning_metrics = LearningMetrics()\n        self.current_learning_focus = None\n        self.learning_queue = asyncio.Queue()\n\n    async def learn_from_execution(self, execution_record: CommandExecutionRecord) -> None:\n        \"\"\"Learn from command execution experience\"\"\"\n        # Extract learning patterns\n        patterns = self._extract_learning_patterns(execution_record)\n        \n        # Create learning experience record\n        experience = LearningExperience(\n            agent_id=self.name,\n            command_execution_id=execution_record.id,\n            expertise_area=self._determine_expertise_area(execution_record),\n            success_metrics=self._calculate_success_metrics(execution_record),\n            learned_patterns=patterns,\n            improvement_areas=self._identify_improvement_areas(execution_record)\n        )\n        \n        # Store in database\n        with self.db_session() as session:\n            session.add(experience)\n            session.commit()\n        \n        # Update learning memory\n        self.learning_memory.add_experience({\n            'command': execution_record.command,\n            'patterns': patterns,\n            'success': experience.success_metrics > 0.7,\n            'key_factors': self._extract_key_factors(execution_record)\n        })\n        \n        # Update metrics\n        await self._update_learning_metrics(experience)\n\n    def _extract_learning_patterns(self, record: CommandExecutionRecord) -> Dict:\n        \"\"\"Extract patterns from command execution\"\"\"\n        return {\n            'command_patterns': self._analyze_command_patterns(record.command),\n            'output_patterns': self._analyze_output_patterns(record.stdout, record.stderr),\n            'state_transition_patterns': self._analyze_state_transitions(\n                record.system_state_before, \n                record.system_state_after\n            ),\n            'interaction_patterns': self._analyze_interactions(record.interaction_history)\n        }\n\n    def _analyze_command_patterns(self, command: str) -> Dict:\n        \"\"\"Analyze command structure and parameters\"\"\"\n        return {\n            'structure': self._extract_command_structure(command),\n            'parameters': self._extract_parameters(command),\n            'common_patterns': self._identify_common_patterns(command)\n        }\n\n    def _analyze_output_patterns(self, stdout: str, stderr: str) -> Dict:\n        \"\"\"Analyze command output patterns\"\"\"\n        return {\n            'success_indicators': self._extract_success_indicators(stdout),\n            'error_patterns': self._extract_error_patterns(stderr),\n            'progress_indicators': self._extract_progress_indicators(stdout)\n        }\n\n    def _analyze_state_transitions(self, \n                                 before: SystemStateSnapshot, \n                                 after: SystemStateSnapshot) -> Dict:\n        \"\"\"Analyze system state changes\"\"\"\n        return {\n            'resource_changes': self._analyze_resource_changes(before, after),\n            'status_transitions': self._analyze_status_transitions(before, after),\n            'critical_changes': self._identify_critical_changes(before, after)\n        }\n\n    async def _update_learning_metrics(self, experience: LearningExperience) -> None:\n        \"\"\"Update agent's learning metrics\"\"\"\n        # Update success rate\n        self.learning_metrics.command_success_rate = (\n            0.9 * self.learning_metrics.command_success_rate +\n            0.1 * experience.success_metrics\n        )\n        \n        # Update pattern recognition score\n        pattern_score = len(experience.learned_patterns) / 10  # normalized score\n        self.learning_metrics.pattern_recognition_score = (\n            0.9 * self.learning_metrics.pattern_recognition_score +\n            0.1 * pattern_score\n        )\n        \n        # Store metrics update\n        with self.db_session() as session:\n            session.add(CommandExecutionRecord(\n                command=\"metrics_update\",\n                agent_decisions={'metrics_update': self.learning_metrics.dict()},\n                learning_annotations={\n                    'pattern_score': pattern_score,\n                    'success_metrics': experience.success_metrics\n                }\n            ))\n            session.commit()\n\n    async def adapt_to_patterns(self) -> None:\n        \"\"\"Adapt behavior based on learned patterns\"\"\"\n        while True:\n            # Get most frequent success patterns\n            top_patterns = sorted(\n                self.learning_memory.success_patterns.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:5]\n            \n            # Adjust behavior based on successful patterns\n            for pattern, frequency in top_patterns:\n                await self._incorporate_pattern(pattern)\n            \n            # Sleep before next adaptation cycle\n            await asyncio.sleep(60)\n\n    async def _incorporate_pattern(self, pattern: str) -> None:\n        \"\"\"Incorporate successful pattern into agent's behavior\"\"\"\n        pattern_data = json.loads(pattern)\n        \n        # Update agent's decision making based on pattern\n        self.knowledge_base.update({\n            'successful_patterns': pattern_data\n        })\n        \n        # Record pattern incorporation\n        with self.db_session() as session:\n            session.add(LearningExperience(\n                agent_id=self.name,\n                expertise_area='pattern_adaptation',\n                learned_patterns={'incorporated_pattern': pattern_data},\n                success_metrics=1.0\n            ))\n            session.commit()\n\nclass LearningOrchestrator:\n    def __init__(self, db_session: sessionmaker):\n        self.db_session = db_session\n        self.agents: Dict[str, LearningProgrammerAgent] = {}\n        self.learning_tasks = []\n\n    def add_agent(self, agent: LearningProgrammerAgent) -> None:\n        \"\"\"Add a learning agent to the orchestrator\"\"\"\n        self.agents[agent.name] = agent\n        self.learning_tasks.append(\n            asyncio.create_task(self._manage_agent_learning(agent))\n        )\n\n    async def _manage_agent_learning(self, agent: LearningProgrammerAgent) -> None:\n        \"\"\"Manage learning process for an agent\"\"\"\n        while True:\n            # Get recent executions\n            with self.db_session() as session:\n                recent_executions = session.query(CommandExecutionRecord)\\\n                    .order_by(CommandExecutionRecord.timestamp.desc())\\\n                    .limit(10)\\\n                    .all()\n\n            # Process each execution for learning\n            for execution in recent_executions:\n                await agent.learn_from_execution(execution)\n\n            # Adapt to learned patterns\n            await agent.adapt_to_patterns()\n            \n            # Sleep before next learning cycle\n            await asyncio.sleep(300)  # 5 minutes between learning cycles\n\n    async def analyze_learning_progress(self) -> Dict:\n        \"\"\"Analyze learning progress across all agents\"\"\"\n        progress_metrics = {}\n        \n        for agent_name, agent in self.agents.items():\n            progress_metrics[agent_name] = {\n                'metrics': agent.learning_metrics.dict(),\n                'top_patterns': self._get_top_patterns(agent),\n                'improvement_areas': self._analyze_improvement_areas(agent)\n            }\n        \n        return progress_metrics\n\n    def _get_top_patterns(self, agent: LearningProgrammerAgent) -> Dict:\n        \"\"\"Get top successful and error patterns for an agent\"\"\"\n        return {\n            'success_patterns': dict(sorted(\n                agent.learning_memory.success_patterns.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:5]),\n            'error_patterns': dict(sorted(\n                agent.learning_memory.error_patterns.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:5])\n        }\n\n# Example usage\nasync def main():\n    # Initialize database\n    engine = create_engine('sqlite:///agent_learning.db')\n    Base.metadata.create_all(engine)\n    Session = sessionmaker(bind=engine)\n    \n    # Create learning orchestrator\n    orchestrator = LearningOrchestrator(Session)\n    \n    # Create learning agents\n    frontend_agent = LearningProgrammerAgent(\n        name=\"frontend_dev\",\n        expertise=[\"frontend\", \"ui\"],\n        model_path=\"small_model_path\",\n        db_session=Session\n    )\n    \n    backend_agent = LearningProgrammerAgent(\n        name=\"backend_dev\",\n        expertise=[\"backend\", \"database\"],\n        model_path=\"small_model_path\",\n        db_session=Session\n    )\n    \n    # Add agents to orchestrator\n    orchestrator.add_agent(frontend_agent)\n    orchestrator.add_agent(backend_agent)\n    \n    # Run learning system\n    while True:\n        progress = await orchestrator.analyze_learning_progress()\n        print(\"Learning Progress:\", json.dumps(progress, indent=2))\n        await asyncio.sleep(3600)  # Analysis every hour\n\nif __name__ == \"__main__\":\n    await main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:00:40.987389Z","iopub.execute_input":"2025-02-27T17:00:40.987706Z","iopub.status.idle":"2025-02-27T17:00:41.105167Z","shell.execute_reply.started":"2025-02-27T17:00:40.987681Z","shell.execute_reply":"2025-02-27T17:00:41.103647Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-2-12c81ffecac6>:13: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n  Base = declarative_base()\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-12c81ffecac6>\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error_factors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBaseAgent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-12c81ffecac6>\u001b[0m in \u001b[0;36mBaseAgent\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknowledge_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceiver\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMessageType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         message = Message(\n\u001b[1;32m     98\u001b[0m             \u001b[0msender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'MessageType' is not defined"],"ename":"NameError","evalue":"name 'MessageType' is not defined","output_type":"error"}],"execution_count":2}]}