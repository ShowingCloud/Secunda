{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade --quiet pydantic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T12:34:38.485016Z","iopub.execute_input":"2025-02-27T12:34:38.485392Z","iopub.status.idle":"2025-02-27T12:34:45.038193Z","shell.execute_reply.started":"2025-02-27T12:34:38.485363Z","shell.execute_reply":"2025-02-27T12:34:45.036838Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from typing import List, Dict, Optional, Union\nfrom pydantic import BaseModel, Field\nfrom enum import Enum\nimport asyncio\nfrom datetime import datetime\nimport json\nfrom dataclasses import dataclass\nfrom collections import deque\n\nclass MessageType(Enum):\n    TASK_ASSIGNMENT = \"task_assignment\"\n    STATUS_UPDATE = \"status_update\"\n    TECHNICAL_QUERY = \"technical_query\"\n    TECHNICAL_RESPONSE = \"technical_response\"\n    FEEDBACK = \"feedback\"\n    IMPROVEMENT_SUGGESTION = \"improvement_suggestion\"\n    TEST_RESULT = \"test_result\"\n\nclass Expertise(Enum):\n    FRONTEND = \"frontend\"\n    BACKEND = \"backend\"\n    DEVOPS = \"devops\"\n    DATABASE = \"database\"\n    TESTING = \"testing\"\n\n@dataclass\nclass TechnologyStack:\n    name: str\n    version: str\n    expertise_area: Expertise\n    required_skills: List[str]\n\nclass Message(BaseModel):\n    sender: str\n    receiver: str\n    msg_type: MessageType\n    content: Dict\n    timestamp: datetime = Field(default_factory=datetime.now)\n    priority: int = 0\n    context: Optional[Dict] = None\n\nclass Task(BaseModel):\n    id: str\n    title: str\n    description: str\n    required_expertise: List[Expertise]\n    assigned_to: Optional[str] = None\n    status: str = \"pending\"\n    dependencies: List[str] = Field(default_factory=list)\n    estimated_time: float\n    actual_time: Optional[float] = None\n    learning_opportunities: List[str] = Field(default_factory=list)\n\nclass AgentMetrics(BaseModel):\n    tasks_completed: int = 0\n    avg_completion_time: float = 0.0\n    skill_improvements: Dict[str, float] = Field(default_factory=dict)\n    learning_activities: List[str] = Field(default_factory=list)\n    feedback_rating: float = 0.0\n\nclass BaseAgent:\n    def __init__(self, name: str, model_path: str):\n        self.name = name\n        self.model_path = model_path\n        self.message_queue = asyncio.Queue()\n        self.metrics = AgentMetrics()\n        self.knowledge_base = {}\n\n    async def send_message(self, receiver: str, msg_type: MessageType, content: Dict):\n        message = Message(\n            sender=self.name,\n            receiver=receiver,\n            msg_type=msg_type,\n            content=content\n        )\n        await self.message_queue.put(message)\n\n    async def receive_message(self) -> Message:\n        return await self.message_queue.get()\n\nclass ArchitectAgent(BaseAgent):\n    def __init__(self, name: str):\n        super().__init__(name, model_path=\"large_model_path\")  # Using large model\n        self.technology_knowledge = {}\n        self.system_design_patterns = {}\n        self.architecture_decisions = []\n\n    async def evaluate_technical_query(self, query: Dict) -> Dict:\n        \"\"\"Evaluate complex technical queries using the large model\"\"\"\n        # Simplified for example\n        return {\n            \"solution\": \"Detailed technical solution\",\n            \"rationale\": \"Architecture considerations\",\n            \"implications\": [\"Impact 1\", \"Impact 2\"]\n        }\n\n    async def review_system_design(self, design: Dict) -> Dict:\n        \"\"\"Review and improve system design\"\"\"\n        # Implementation using large model for complex reasoning\n        pass\n\n    async def maintain_technical_standards(self) -> None:\n        \"\"\"Update and maintain technical standards\"\"\"\n        pass\n\nclass ProjectManagerAgent(BaseAgent):\n    def __init__(self, name: str):\n        super().__init__(name, model_path=\"small_model_path\")  # Using small model\n        self.task_queue = deque()\n        self.team_metrics = {}\n        self.learning_programs = {}\n\n    async def assign_task(self, task: Task, team: Dict[str, 'ProgrammerAgent']) -> None:\n        \"\"\"Assign tasks based on expertise and current workload\"\"\"\n        best_programmer = None\n        min_workload = float('inf')\n\n        for programmer in team.values():\n            if (any(exp in programmer.expertise for exp in task.required_expertise) and \n                len(programmer.current_tasks) < min_workload):\n                best_programmer = programmer\n                min_workload = len(programmer.current_tasks)\n\n        if best_programmer:\n            task.assigned_to = best_programmer.name\n            await self.send_message(\n                best_programmer.name,\n                MessageType.TASK_ASSIGNMENT,\n                {\"task\": task.dict()}\n            )\n\n    async def monitor_progress(self, team: Dict[str, 'ProgrammerAgent']) -> None:\n        \"\"\"Monitor team progress and provide feedback\"\"\"\n        for programmer in team.values():\n            metrics = programmer.metrics\n            if metrics.tasks_completed > 0:\n                await self.send_message(\n                    programmer.name,\n                    MessageType.FEEDBACK,\n                    {\n                        \"performance\": metrics.dict(),\n                        \"suggestions\": self.generate_improvement_suggestions(metrics)\n                    }\n                )\n\n    def generate_improvement_suggestions(self, metrics: AgentMetrics) -> List[str]:\n        \"\"\"Generate personalized improvement suggestions using small model\"\"\"\n        # Implementation using small model for basic analysis\n        pass\n\nclass ProgrammerAgent(BaseAgent):\n    def __init__(self, name: str, expertise: List[Expertise]):\n        super().__init__(name, model_path=\"small_model_path\")  # Using small model\n        self.expertise = expertise\n        self.current_tasks: List[Task] = []\n        self.learning_goals = {}\n        self.test_results = []\n\n    async def work_on_task(self, task: Task) -> None:\n        \"\"\"Work on assigned task\"\"\"\n        # Implementation using small model for specific technology tasks\n        self.current_tasks.append(task)\n        \n        # Simulate task work\n        await asyncio.sleep(task.estimated_time)\n        \n        # Update metrics\n        self.metrics.tasks_completed += 1\n        self.metrics.avg_completion_time = (\n            (self.metrics.avg_completion_time * (self.metrics.tasks_completed - 1) + \n             task.estimated_time) / self.metrics.tasks_completed\n        )\n\n    async def run_tests(self) -> None:\n        \"\"\"Run tests in spare time\"\"\"\n        if not self.current_tasks:  # Only run tests when not working on tasks\n            test_result = {\n                \"coverage\": 85.5,\n                \"passed\": 42,\n                \"failed\": 3,\n                \"learning_points\": [\"Point 1\", \"Point 2\"]\n            }\n            self.test_results.append(test_result)\n            \n            # Update learning metrics\n            self.metrics.learning_activities.append(\"Unit Testing\")\n            self.metrics.skill_improvements[\"testing\"] = \\\n                self.metrics.skill_improvements.get(\"testing\", 0) + 0.1\n\n    async def request_technical_help(self, problem: Dict) -> None:\n        \"\"\"Request help from architect for complex issues\"\"\"\n        await self.send_message(\n            \"architect\",\n            MessageType.TECHNICAL_QUERY,\n            {\n                \"problem\": problem,\n                \"context\": {\n                    \"expertise\": [e.value for e in self.expertise],\n                    \"current_task\": self.current_tasks[-1].dict() if self.current_tasks else None\n                }\n            }\n        )\n\nclass MultiAgentSystem:\n    def __init__(self):\n        self.architect = ArchitectAgent(\"architect\")\n        self.project_manager = ProjectManagerAgent(\"project_manager\")\n        self.programmers: Dict[str, ProgrammerAgent] = {}\n        self.message_broker = asyncio.Queue()\n\n    def add_programmer(self, name: str, expertise: List[Expertise]) -> None:\n        \"\"\"Add a new programmer to the system\"\"\"\n        self.programmers[name] = ProgrammerAgent(name, expertise)\n\n    async def route_message(self, message: Message) -> None:\n        \"\"\"Route messages between agents\"\"\"\n        if message.receiver == \"architect\":\n            await self.architect.message_queue.put(message)\n        elif message.receiver == \"project_manager\":\n            await self.project_manager.message_queue.put(message)\n        elif message.receiver in self.programmers:\n            await self.programmers[message.receiver].message_queue.put(message)\n\n    async def run(self) -> None:\n        \"\"\"Run the multi-agent system\"\"\"\n        # Start all agent tasks\n        tasks = [\n            self.architect.maintain_technical_standards(),\n            self.project_manager.monitor_progress(self.programmers)\n        ]\n        \n        # Add programmer tasks\n        for programmer in self.programmers.values():\n            tasks.extend([\n                programmer.run_tests(),  # Run tests in spare time\n                self._process_agent_messages(programmer)\n            ])\n\n        await asyncio.gather(*tasks)\n\n    async def _process_agent_messages(self, agent: BaseAgent) -> None:\n        \"\"\"Process messages for an agent\"\"\"\n        while True:\n            message = await agent.receive_message()\n            # Route message to appropriate handler based on type\n            if message.msg_type == MessageType.TASK_ASSIGNMENT:\n                await self._handle_task_assignment(agent, message)\n            elif message.msg_type == MessageType.TECHNICAL_QUERY:\n                await self._handle_technical_query(message)\n            # Add other message type handlers as needed\n\n    async def _handle_task_assignment(self, agent: ProgrammerAgent, message: Message) -> None:\n        \"\"\"Handle task assignment messages\"\"\"\n        task = Task(**message.content[\"task\"])\n        await agent.work_on_task(task)\n\n    async def _handle_technical_query(self, message: Message) -> None:\n        \"\"\"Handle technical query messages\"\"\"\n        response = await self.architect.evaluate_technical_query(message.content)\n        await self.route_message(\n            Message(\n                sender=\"architect\",\n                receiver=message.sender,\n                msg_type=MessageType.TECHNICAL_RESPONSE,\n                content=response\n            )\n        )\n\n# Example usage\nasync def main():\n    system = MultiAgentSystem()\n    \n    # Add programmers with different expertise\n    system.add_programmer(\"frontend_dev\", [Expertise.FRONTEND])\n    system.add_programmer(\"backend_dev\", [Expertise.BACKEND, Expertise.DATABASE])\n    system.add_programmer(\"devops_dev\", [Expertise.DEVOPS])\n    \n    # Create some tasks\n    tasks = [\n        Task(\n            id=\"task1\",\n            title=\"Implement user authentication\",\n            description=\"Implement OAuth2 authentication flow\",\n            required_expertise=[Expertise.BACKEND],\n            estimated_time=4.0\n        ),\n        Task(\n            id=\"task2\",\n            title=\"Design responsive UI\",\n            description=\"Create responsive dashboard layout\",\n            required_expertise=[Expertise.FRONTEND],\n            estimated_time=3.0\n        )\n    ]\n    \n    # Assign tasks\n    for task in tasks:\n        await system.project_manager.assign_task(task, system.programmers)\n    \n    # Run the system\n    await system.run()\n\nif __name__ == \"__main__\":\n    await main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T12:34:45.040130Z","iopub.execute_input":"2025-02-27T12:34:45.040855Z","execution_failed":"2025-02-27T12:34:53.936Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-2-c74cc90946c2>:129: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n  {\"task\": task.dict()}\n","output_type":"stream"},{"name":"stdout","text":"[<coroutine object ArchitectAgent.maintain_technical_standards at 0x7924a281bd10>, <coroutine object ProjectManagerAgent.monitor_progress at 0x7924a281be60>, <coroutine object ProgrammerAgent.run_tests at 0x7924a281bdf0>, <coroutine object MultiAgentSystem._process_agent_messages at 0x7924a281b990>, <coroutine object ProgrammerAgent.run_tests at 0x7924a281ba70>, <coroutine object MultiAgentSystem._process_agent_messages at 0x7924a281bed0>, <coroutine object ProgrammerAgent.run_tests at 0x7924a281b920>, <coroutine object MultiAgentSystem._process_agent_messages at 0x7924a281bae0>]\n","output_type":"stream"}],"execution_count":null}]}