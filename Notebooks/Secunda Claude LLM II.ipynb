{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nBase Agent Framework for Multi-Agent System\n- Defines core agent structure\n- Implements Model Context Protocol (MCP)\n- Handles communication between agents\n\"\"\"\n\nimport os\nimport json\nimport asyncio\nimport logging\nfrom typing import Dict, List, Optional, Any, Set, Tuple\nfrom enum import Enum, auto\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom collections import deque\nimport uuid\nfrom pydantic import BaseModel, Field\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n# ====== Context Definitions (MCP) ======\n\nclass ContextType(Enum):\n    \"\"\"Types of contexts that can be shared between agents\"\"\"\n    SYSTEM = auto()       # System-wide information\n    TASK = auto()         # Task-related information\n    COMMAND = auto()      # Command execution details\n    LEARNING = auto()     # Learning-related information\n    THOUGHT = auto()      # Internal thought processes\n    MESSAGE = auto()      # Direct messages between agents\n\nclass Context(BaseModel):\n    \"\"\"Base context class using Model Context Protocol\"\"\"\n    context_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    context_type: ContextType\n    created_at: datetime = Field(default_factory=datetime.now)\n    source_agent: str\n    target_agents: List[str] = Field(default_factory=list)\n    priority: int = 1  # 1-10, higher is more important\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    content: Dict[str, Any] = Field(default_factory=dict)\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert context to dictionary for transmission\"\"\"\n        return {\n            \"context_id\": self.context_id,\n            \"context_type\": self.context_type.name,\n            \"created_at\": self.created_at.isoformat(),\n            \"source_agent\": self.source_agent,\n            \"target_agents\": self.target_agents,\n            \"priority\": self.priority,\n            \"metadata\": self.metadata,\n            \"content\": self.content\n        }\n\n# ====== Thought Process ======\n\nclass ThoughtType(Enum):\n    \"\"\"Types of thoughts an agent can have\"\"\"\n    OBSERVATION = auto()  # Raw observations\n    ANALYSIS = auto()     # Analysis of observations\n    PLAN = auto()         # Planning future actions\n    DECISION = auto()     # Making decisions\n    LEARNING = auto()     # Learning from experiences\n    REFLECTION = auto()   # Reflecting on past actions\n\nclass Thought(BaseModel):\n    \"\"\"Represents an internal thought process of an agent\"\"\"\n    thought_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    thought_type: ThoughtType\n    created_at: datetime = Field(default_factory=datetime.now)\n    content: str\n    confidence: float = 0.5  # 0.0-1.0, higher is more confident\n    references: List[str] = Field(default_factory=list)  # IDs of related thoughts\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n\n# ====== Memory System ======\n\nclass Memory(BaseModel):\n    \"\"\"Base memory class for agents\"\"\"\n    memories: Dict[str, Thought] = Field(default_factory=dict)\n    short_term: List[str] = Field(default_factory=list)  # Recent thought IDs\n    long_term: Dict[str, List[str]] = Field(default_factory=dict)  # Categorized thought IDs\n    patterns: Dict[str, Dict[str, float]] = Field(default_factory=dict)  # Pattern: {thought_id: confidence}\n    \n    def add_thought(self, thought: Thought) -> None:\n        \"\"\"Add a thought to memory\"\"\"\n        self.memories[thought.thought_id] = thought\n        self.short_term.append(thought.thought_id)\n        \n        # Limit short-term memory size\n        if len(self.short_term) > 50:\n            self.short_term.pop(0)\n        \n        # Categorize in long-term memory\n        category = thought.thought_type.name\n        if category not in self.long_term:\n            self.long_term[category] = []\n        self.long_term[category].append(thought.thought_id)\n    \n    def get_relevant_thoughts(self, query: str, thought_types: Optional[List[ThoughtType]] = None, \n                             limit: int = 5) -> List[Thought]:\n        \"\"\"Retrieve relevant thoughts based on a query\"\"\"\n        # Simple relevance scoring based on content matching\n        # In production, use vector embeddings or more sophisticated retrieval\n        relevant_thoughts = []\n        \n        for thought_id, thought in self.memories.items():\n            # Filter by thought type if specified\n            if thought_types and thought.thought_type not in thought_types:\n                continue\n                \n            # Simple relevance check (to be replaced with better matching)\n            relevance = 0\n            for word in query.lower().split():\n                if word in thought.content.lower():\n                    relevance += 1\n            \n            if relevance > 0:\n                relevant_thoughts.append((thought, relevance))\n        \n        # Sort by relevance and return top results\n        relevant_thoughts.sort(key=lambda x: x[1], reverse=True)\n        return [t[0] for t in relevant_thoughts[:limit]]\n\n# ====== Base Agent ======\n\nclass AgentRole(Enum):\n    \"\"\"Roles that agents can have in the system\"\"\"\n    ARCHITECT = auto()\n    PROJECT_MANAGER = auto()\n    PROGRAMMER = auto()\n    SPECIALIST = auto()\n\nclass AgentStatus(Enum):\n    \"\"\"Possible statuses of an agent\"\"\"\n    INITIALIZING = auto()\n    READY = auto()\n    BUSY = auto()\n    LEARNING = auto()\n    OFFLINE = auto()\n\nclass BaseAgent:\n    \"\"\"Base class for all agents in the system\"\"\"\n    \n    def __init__(self, agent_id: str, role: AgentRole, model_path: str):\n        self.agent_id = agent_id\n        self.role = role\n        self.model_path = model_path\n        self.status = AgentStatus.INITIALIZING\n        self.memory = Memory()\n        self.context_queue = asyncio.Queue()\n        self.subscribed_contexts: Set[ContextType] = set()\n        self.model = None  # To be loaded by subclasses\n        self.logger = logging.getLogger(f\"agent.{agent_id}\")\n        \n    async def initialize(self) -> None:\n        \"\"\"Initialize the agent and load model\"\"\"\n        self.logger.info(f\"Initializing agent {self.agent_id}\")\n        # Load model - to be implemented by subclasses\n        await self._load_model()\n        self.status = AgentStatus.READY\n        \n    async def _load_model(self) -> None:\n        \"\"\"Load the language model - to be implemented by subclasses\"\"\"\n        raise NotImplementedError(\"Subclasses must implement _load_model\")\n    \n    def subscribe_to_context(self, context_type: ContextType) -> None:\n        \"\"\"Subscribe to a specific context type\"\"\"\n        self.subscribed_contexts.add(context_type)\n    \n    async def receive_context(self, context: Context) -> None:\n        \"\"\"Receive a context and add it to the queue\"\"\"\n        if context.context_type in self.subscribed_contexts:\n            await self.context_queue.put(context)\n    \n    async def send_context(self, context: Context, message_broker) -> None:\n        \"\"\"Send a context through the message broker\"\"\"\n        context.source_agent = self.agent_id\n        await message_broker.publish_context(context)\n    \n    async def process_contexts(self, message_broker) -> None:\n        \"\"\"Process contexts from the queue\"\"\"\n        while True:\n            context = await self.context_queue.get()\n            self.logger.debug(f\"Processing context: {context.context_id}\")\n            \n            # Process based on context type\n            if context.context_type == ContextType.MESSAGE:\n                await self._process_message(context)\n            elif context.context_type == ContextType.TASK:\n                await self._process_task(context)\n            elif context.context_type == ContextType.COMMAND:\n                await self._process_command(context)\n            elif context.context_type == ContextType.LEARNING:\n                await self._process_learning(context)\n            else:\n                await self._process_other_context(context)\n                \n            # Mark as done\n            self.context_queue.task_done()\n    \n    async def _process_message(self, context: Context) -> None:\n        \"\"\"Process a message context - to be implemented by subclasses\"\"\"\n        raise NotImplementedError(\"Subclasses must implement _process_message\")\n    \n    async def _process_task(self, context: Context) -> None:\n        \"\"\"Process a task context - to be implemented by subclasses\"\"\"\n        raise NotImplementedError(\"Subclasses must implement _process_task\")\n    \n    async def _process_command(self, context: Context) -> None:\n        \"\"\"Process a command context - to be implemented by subclasses\"\"\"\n        raise NotImplementedError(\"Subclasses must implement _process_command\")\n    \n    async def _process_learning(self, context: Context) -> None:\n        \"\"\"Process a learning context - to be implemented by subclasses\"\"\"\n        raise NotImplementedError(\"Subclasses must implement _process_learning\")\n    \n    async def _process_other_context(self, context: Context) -> None:\n        \"\"\"Process other context types - to be implemented by subclasses\"\"\"\n        raise NotImplementedError(\"Subclasses must implement _process_other_context\")\n    \n    async def generate_thought(self, thought_type: ThoughtType, content_prompt: str) -> Thought:\n        \"\"\"Generate an internal thought using the agent's LLM\"\"\"\n        # To be implemented with actual LLM generation in subclasses\n        raise NotImplementedError(\"Subclasses must implement generate_thought\")\n    \n    async def shutdown(self) -> None:\n        \"\"\"Cleanly shutdown the agent\"\"\"\n        self.logger.info(f\"Shutting down agent {self.agent_id}\")\n        self.status = AgentStatus.OFFLINE\n        # Additional cleanup to be implemented by subclasses\n\n# ====== Message Broker ======\n\nclass MessageBroker:\n    \"\"\"Handles communication between agents\"\"\"\n    \n    def __init__(self):\n        self.agents: Dict[str, BaseAgent] = {}\n        self.context_handlers: Dict[ContextType, List[str]] = {}\n        self.logger = logging.getLogger(\"message_broker\")\n    \n    def register_agent(self, agent: BaseAgent) -> None:\n        \"\"\"Register an agent with the broker\"\"\"\n        self.agents[agent.agent_id] = agent\n        \n        # Register context subscriptions\n        for context_type in agent.subscribed_contexts:\n            if context_type not in self.context_handlers:\n                self.context_handlers[context_type] = []\n            self.context_handlers[context_type].append(agent.agent_id)\n    \n    async def publish_context(self, context: Context) -> None:\n        \"\"\"Publish a context to relevant agents\"\"\"\n        self.logger.debug(f\"Publishing context: {context.context_id}\")\n        \n        target_agents = []\n        \n        # If specific targets are specified\n        if context.target_agents:\n            target_agents = [agent_id for agent_id in context.target_agents if agent_id in self.agents]\n        # Otherwise, send to all subscribed agents\n        else:\n            target_agents = self.context_handlers.get(context.context_type, [])\n        \n        # Send to each target agent\n        for agent_id in target_agents:\n            if agent_id != context.source_agent:  # Don't send back to source\n                await self.agents[agent_id].receive_context(context)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}