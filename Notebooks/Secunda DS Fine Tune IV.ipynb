{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\nfrom peft import LoraConfig, get_peft_model, TaskType\n\n# 基础模型\nmodel = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n\n# Step 1: 定义共享的LoRA配置 (基础层)\nshared_lora_config = LoraConfig(\n    r=8,  # 较高秩捕获通用特征\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],  # 作用于注意力层\n    lora_dropout=0.1,\n    task_type=TaskType.CAUSAL_LM,\n    # 关键：标记为共享参数（通过名称区分）\n    name=\"shared_lora\"  \n)\n\n# Step 2: 添加共享适配器到基础模型\nmodel = get_peft_model(model, shared_lora_config)\n\n# Step 3: 为每个任务添加任务特定适配器 (低秩)\ntask1_lora_config = LoraConfig(\n    r=4,  # 低秩适应任务差异\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.1,\n    task_type=TaskType.CAUSAL_LM,\n    name=\"task1_lora\",\n    # 关键：与共享适配器模块相同，但独立参数\n    layers_to_transform=shared_lora_config.layers_to_transform  \n)\nmodel.add_adapter(task1_lora_config, \"task1\")\n\ntask2_lora_config = LoraConfig(...)  # 类似定义\nmodel.add_adapter(task2_lora_config, \"task2\")\n\n# 激活共享适配器 + 任务适配器组合\ndef activate_combined_adapter(task_name):\n    model.set_adapter([\"shared_lora\", task_name])  # 组合参数","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom datasets import load_dataset\n\n# 假设 task1_data 和 task2_data 已加载\ntrain_loader1 = DataLoader(task1_data, batch_size=4, shuffle=True)\ntrain_loader2 = DataLoader(task2_data, batch_size=4, shuffle=True)\n\n# 优化器：区分共享参数和任务参数\nshared_params = [p for n, p in model.named_parameters() if \"shared_lora\" in n]\ntask1_params = [p for n, p in model.named_parameters() if \"task1_lora\" in n]\ntask2_params = [p for n, p in model.named_parameters() if \"task2_lora\" in n]\n\noptimizer = torch.optim.AdamW([\n    {\"params\": shared_params, \"lr\": 1e-5},\n    {\"params\": task1_params, \"lr\": 1e-4},\n    {\"params\": task2_params, \"lr\": 1e-4}\n])\n\n# 交替训练循环\nfor epoch in range(10):\n    # 混合数据迭代器（交替批次）\n    mixed_loader = zip(train_loader1, train_loader2)\n    for batch1, batch2 in mixed_loader:\n        # 训练任务1\n        activate_combined_adapter(\"task1_lora\")\n        outputs = model(**batch1)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        # 训练任务2\n        activate_combined_adapter(\"task2_lora\")\n        outputs = model(**batch2)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 阶段1：仅训练共享参数\nfor param in model.parameters():\n    if \"lora\" in name and \"shared_lora\" not in name:\n        param.requires_grad = False  # 冻结任务特定参数\n\noptimizer = torch.optim.AdamW(shared_params, lr=1e-5)\nfor epoch in range(5):\n    for batch in combined_data_loader:  # 混合所有任务数据\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n# 阶段2：解冻任务参数并微调\nfor param in model.parameters():\n    param.requires_grad = True  # 解冻所有参数（共享+任务）\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\nfor epoch in range(5):\n    # 正常多任务训练（如交替训练）","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 假设已有一个预训练的教师模型\nteacher_model = AutoModelForCausalLM.from_pretrained(\"teacher_model\")\nteacher_model.eval()\n\n# 学生模型（带共享+任务适配器）\nstudent_model = get_peft_model(...)  # 同第一部分\n\n# 蒸馏损失函数\ndef compute_distill_loss(student_logits, teacher_logits, labels, alpha=0.5):\n    ce_loss = F.cross_entropy(student_logits, labels)\n    kl_loss = F.kl_div(\n        F.log_softmax(student_logits, dim=-1),\n        F.softmax(teacher_logits, dim=-1),\n        reduction=\"batchmean\"\n    )\n    return alpha * ce_loss + (1 - alpha) * kl_loss\n\n# 训练步骤\nfor batch in data_loader:\n    # 教师推理\n    with torch.no_grad():\n        teacher_outputs = teacher_model(**batch)\n    \n    # 学生推理\n    student_outputs = student_model(**batch)\n    \n    # 计算混合损失\n    loss = compute_distill_loss(\n        student_outputs.logits,\n        teacher_outputs.logits,\n        batch[\"labels\"]\n    )\n    loss.backward()\n    optimizer.step()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 假设已有训练好的共享适配器 \"shared_lora\"\n# 新任务适配器 \"task3_lora\" 初始化时复用共享参数\n\n# 获取共享适配器权重\nshared_state_dict = {\n    k: v.clone() for k, v in model.state_dict().items()\n    if \"shared_lora\" in k\n}\n\n# 添加新任务适配器\ntask3_lora_config = LoraConfig(...)\nmodel.add_adapter(task3_lora_config, \"task3\")\n\n# 初始化新适配器参数：部分继承共享权重\nfor name, param in model.named_parameters():\n    if \"task3_lora\" in name:\n        # 例如：继承共享的A矩阵，随机初始化B矩阵\n        if \"lora_A\" in name:\n            param.data.copy_(shared_state_dict[name.replace(\"task3\", \"shared\")])\n        elif \"lora_B\" in name:\n            torch.nn.init.kaiming_uniform_(param.data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 训练时保存多个适配器权重\nmodel.save_pretrained_adapters(\"adapters/\", [\"shared_lora\", \"task1_lora\", \"task2_lora\"])\n\n# 推理时动态加权融合\ndef fuse_adapters(weights):\n    fused_state_dict = {}\n    for adapter_name in [\"shared_lora\", \"task1_lora\", \"task2_lora\"]:\n        adapter_state = torch.load(f\"adapters/{adapter_name}/adapter_model.bin\")\n        for key in adapter_state:\n            if key not in fused_state_dict:\n                fused_state_dict[key] = weights[adapter_name] * adapter_state[key]\n            else:\n                fused_state_dict[key] += weights[adapter_name] * adapter_state[key]\n    model.load_state_dict(fused_state_dict, strict=False)\n\n# 示例：平均权重\nfuse_adapters({\"shared_lora\": 0.5, \"task1_lora\": 0.3, \"task2_lora\": 0.2})","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}